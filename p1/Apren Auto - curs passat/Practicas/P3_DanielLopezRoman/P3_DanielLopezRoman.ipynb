{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 03 - Para entregar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se trata de aplicar los cuatro métodos de ajustar y validar el modelo, razonando detalladamente en el informe la justificación de elegir un modelo:\n",
    "\n",
    "1. Clasificación en un problema con dos clases.\n",
    "\n",
    "2. Clasificación en un problema con más de dos clases.\n",
    "\n",
    "2. Regresión: seleccionar por crossvalidación un conjunto óptimo de predictores usando, por ejemplo, la estrategia \"forward\" (para menor engorro) comparando con el resultado de `step`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV variancia alta, Bootstrap bias alto, LOO alto coste computacional\n",
    "\n",
    "Muchos datos = la variancia no es un problema = CV es mejor/su defecto pierde peso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: class\n"
     ]
    }
   ],
   "source": [
    "#install.packages(\"class\",dependencies=TRUE,repos=\"https://cloud.r-project.org\")\n",
    "require(class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfoldIndexes<-function(n,k){\n",
    "    l<-floor(n/k)\n",
    "    Indexes<-c(1,(1:k)*l)\n",
    "    Indexes[k+1]<-n\n",
    "    return(Indexes)\n",
    "    }\n",
    "\n",
    "\n",
    "# lista de las \"k\" del knn\n",
    "ks<-c(3,5,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Clasificador de dos clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: ElemStatLearn\n",
      "Warning message:\n",
      "\"package 'ElemStatLearn' was built under R version 3.4.4\""
     ]
    }
   ],
   "source": [
    "require(ElemStatLearn)\n",
    "data(spam)\n",
    "spam$spam <- as.factor(spam$spam)\n",
    "\n",
    "set<-spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>920</li>\n",
       "\t<li>1840</li>\n",
       "\t<li>2760</li>\n",
       "\t<li>3680</li>\n",
       "\t<li>4601</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 920\n",
       "\\item 1840\n",
       "\\item 2760\n",
       "\\item 3680\n",
       "\\item 4601\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 920\n",
       "3. 1840\n",
       "4. 2760\n",
       "5. 3680\n",
       "6. 4601\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]    1  920 1840 2760 3680 4601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>920</li>\n",
       "\t<li>1840</li>\n",
       "\t<li>2760</li>\n",
       "\t<li>3680</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 920\n",
       "\\item 1840\n",
       "\\item 2760\n",
       "\\item 3680\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 920\n",
       "3. 1840\n",
       "4. 2760\n",
       "5. 3680\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]    1  920 1840 2760 3680"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>920</li>\n",
       "\t<li>1840</li>\n",
       "\t<li>2760</li>\n",
       "\t<li>3680</li>\n",
       "\t<li>4601</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 920\n",
       "\\item 1840\n",
       "\\item 2760\n",
       "\\item 3680\n",
       "\\item 4601\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 920\n",
       "2. 1840\n",
       "3. 2760\n",
       "4. 3680\n",
       "5. 4601\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  920 1840 2760 3680 4601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n<-nrow(set)\n",
    "\n",
    "# Fijamos un 'K' para k-fold cross-validation (pongo mayúscula para no confundir con la k de knn)\n",
    "K<-5\n",
    "J<-kfoldIndexes(n,K)\n",
    "J\n",
    "Lower<-J[-(K+1)]\n",
    "Upper<-J[-1]\n",
    "Lower\n",
    "Upper\n",
    "# Una permutación aleatoria de los índices\n",
    "I<-sample(1:n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"K=  3\"\n",
      "[1] 0.195 0.190 0.207 0.184 0.185\n",
      "[1] 0.192\n",
      "[1] \"K=  5\"\n",
      "[1] 0.198 0.203 0.204 0.192 0.198\n",
      "[1] 0.199\n",
      "[1] \"K=  7\"\n",
      "[1] 0.200 0.214 0.214 0.193 0.205\n",
      "[1] 0.205\n"
     ]
    }
   ],
   "source": [
    "#cross ajustado a las columnas del dataset spam\n",
    "\n",
    "for (k in ks){\n",
    "    \n",
    "    P.ERR<-rep(0,K)\n",
    "    for (fold in 1:K){\n",
    "        Itest<-I[Lower[fold]:(Upper[fold]-1)]\n",
    "        set.test<-set[Itest,]\n",
    "        set.train<-set[-Itest,]\n",
    "        Xtrain<-as.matrix(set.train[,-length(names(set))])\n",
    "        ytrain<-set.train[,length(names(set))]\n",
    "        Xtest<-as.matrix(set.test[,-length(names(set))])\n",
    "        ytest<-set.test[,length(names(set))]\n",
    "        y.hat<-knn(Xtrain,Xtest,ytrain,k)\n",
    "        C<-table(\"True\"=ytest,\"Predicted\"=y.hat)\n",
    "        ntest<-sum(C)\n",
    "        P.ERR[fold]<-(ntest-sum(diag(C)))/ntest\n",
    "        }\n",
    "\n",
    "    print(paste(\"K= \", k))\n",
    "    print(round(P.ERR,3))\n",
    "    mean.p.err<-mean(P.ERR)\n",
    "    print(round(mean.p.err,3))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"K=  3\"\n",
      "[1] 0.187\n",
      "[1] \"K=  5\"\n",
      "[1] 0.188\n",
      "[1] \"K=  7\"\n",
      "[1] 0.197\n"
     ]
    }
   ],
   "source": [
    "#LOO ajustado a las columnas del dataset spam\n",
    "\n",
    "for (k in ks){\n",
    "    \n",
    "    g<-nlevels(set$spam)\n",
    "    C<-matrix(0,nrow=g,ncol=g)\n",
    "    for (i in 1:n){\n",
    "        set.test<-set[i,]\n",
    "        set.train<-set[-i,]\n",
    "        Xtrain<-as.matrix(set.train[,-length(names(set))])\n",
    "        ytrain<-set.train[,length(names(set))]\n",
    "        Xtest<-as.matrix(set.test[,-length(names(set))])\n",
    "        ytest<-set.test[,length(names(set))]\n",
    "        y.hat<-knn(Xtrain,Xtest,ytrain,k)\n",
    "        C[ytest,y.hat]=C[ytest,y.hat]+1\n",
    "        }\n",
    "    \n",
    "    print(paste(\"K= \", k))\n",
    "    p.err<-(n-sum(diag(C)))/n\n",
    "    print(round(p.err,3))\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"K=  3\"\n",
      " [1] 0.198 0.208 0.202 0.198 0.216 0.211 0.210 0.199 0.218 0.209\n",
      "[1] 0.207\n",
      "[1] \"K=  5\"\n",
      " [1] 0.204 0.206 0.201 0.215 0.216 0.199 0.198 0.204 0.205 0.218\n",
      "[1] 0.207\n",
      "[1] \"K=  7\"\n",
      " [1] 0.206 0.204 0.222 0.213 0.205 0.217 0.202 0.209 0.235 0.212\n",
      "[1] 0.213\n"
     ]
    }
   ],
   "source": [
    "#Boot ajustado a las columnas del dataset spam\n",
    "\n",
    "for (k in ks){\n",
    "    \n",
    "    I<-1:n\n",
    "    # Número de remuestras bootstrap\n",
    "    B<-10\n",
    "    P.ERR<-rep(0,B)\n",
    "    for (b in 1:B){\n",
    "        Ib<-sample(I,n,replace = TRUE)\n",
    "        oob<-I[is.na(match(I,Ib))]\n",
    "        Itest<-oob\n",
    "        ntest<-length(oob)\n",
    "        set.test<-set[Itest,]\n",
    "        set.train<-set[-Itest,]\n",
    "        Xtrain<-as.matrix(set.train[,-length(names(set))])\n",
    "        ytrain<-set.train[,length(names(set))]\n",
    "        Xtest<-as.matrix(set.test[,-length(names(set))])\n",
    "        ytest<-set.test[,length(names(set))]\n",
    "        y.hat<-knn(Xtrain,Xtest,ytrain,k)\n",
    "        C<-table(\"True\"=ytest,\"Predicted\"=y.hat)\n",
    "        P.ERR[b]<-(ntest-sum(diag(C)))/ntest\n",
    "        }\n",
    "    \n",
    "    print(paste(\"K= \", k))\n",
    "    print(round(P.ERR,3))\n",
    "    mean.p.err<-mean(P.ERR)\n",
    "    print(round(mean.p.err,3))\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores de k (3, 5, 7) son elegidos a dedo basados en lo observado en la teoria, no son valores muy altos ni 1 o 2.\n",
    "\n",
    "El mejor parece LOO pero tarda una eternidad (es lo normal, es un metodo muy pesado con muchas iteraciones y modelos).\n",
    "\n",
    "En mi opinion es mejor el CV, no es lento ni el peor. En cuanto a la \"k\", no hay mucha diferencia entre usar 3 o 5 aunque puede que sea caer en el overfitting. 7 da unos resultados algo peores, pero mas o menos despreciable en este caso (muy pequeña desviacion en el CV), y a la larga ese clasificador no caera tanto en el overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Clasificador de mas de dos clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t150 obs. of  5 variables:\n",
      " $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n",
      " $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n",
      " $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n",
      " $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n",
      " $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n"
     ]
    }
   ],
   "source": [
    "require(ElemStatLearn)\n",
    "data(iris)\n",
    "str(iris)\n",
    "\n",
    "set<-iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>30</li>\n",
       "\t<li>60</li>\n",
       "\t<li>90</li>\n",
       "\t<li>120</li>\n",
       "\t<li>150</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 30\n",
       "\\item 60\n",
       "\\item 90\n",
       "\\item 120\n",
       "\\item 150\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 30\n",
       "3. 60\n",
       "4. 90\n",
       "5. 120\n",
       "6. 150\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]   1  30  60  90 120 150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>30</li>\n",
       "\t<li>60</li>\n",
       "\t<li>90</li>\n",
       "\t<li>120</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 30\n",
       "\\item 60\n",
       "\\item 90\n",
       "\\item 120\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 30\n",
       "3. 60\n",
       "4. 90\n",
       "5. 120\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]   1  30  60  90 120"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>30</li>\n",
       "\t<li>60</li>\n",
       "\t<li>90</li>\n",
       "\t<li>120</li>\n",
       "\t<li>150</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 30\n",
       "\\item 60\n",
       "\\item 90\n",
       "\\item 120\n",
       "\\item 150\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 30\n",
       "2. 60\n",
       "3. 90\n",
       "4. 120\n",
       "5. 150\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  30  60  90 120 150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n<-nrow(set)\n",
    "\n",
    "# Fijamos un 'K' para k-fold cross-validation (pongo mayúscula para no confundir con la k de knn)\n",
    "K<-5\n",
    "J<-kfoldIndexes(n,K)\n",
    "J\n",
    "Lower<-J[-(K+1)]\n",
    "Upper<-J[-1]\n",
    "Lower\n",
    "Upper\n",
    "# Una permutación aleatoria de los índices\n",
    "I<-sample(1:n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"K=  3\"\n",
      "[1] 0.000 0.100 0.033 0.000 0.033\n",
      "[1] 0.033\n",
      "[1] \"K=  5\"\n",
      "[1] 0.000 0.033 0.100 0.000 0.033\n",
      "[1] 0.033\n",
      "[1] \"K=  7\"\n",
      "[1] 0.000 0.033 0.100 0.000 0.067\n",
      "[1] 0.04\n"
     ]
    }
   ],
   "source": [
    "#cross\n",
    "for (k in ks){\n",
    "    P.ERR<-rep(0,K)\n",
    "    for (fold in 1:K){\n",
    "        Itest<-I[Lower[fold]:(Upper[fold]-1)]\n",
    "        set.test<-set[Itest,]\n",
    "        set.train<-set[-Itest,]\n",
    "        Xtrain<-as.matrix(set.train[,-length(names(set))])\n",
    "        ytrain<-set.train[,length(names(set))]\n",
    "        Xtest<-as.matrix(set.test[,-length(names(set))])\n",
    "        ytest<-set.test[,length(names(set))]\n",
    "        y.hat<-knn(Xtrain,Xtest,ytrain,k)\n",
    "        C<-table(\"True\"=ytest,\"Predicted\"=y.hat)\n",
    "        ntest<-sum(C)\n",
    "        P.ERR[fold]<-(ntest-sum(diag(C)))/ntest\n",
    "    }\n",
    "    print(paste(\"K= \", k))\n",
    "    print(round(P.ERR,3))\n",
    "    mean.p.err<-mean(P.ERR)\n",
    "    print(round(mean.p.err,3))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"K=  3\"\n",
      "[1] 0.04\n",
      "[1] \"K=  5\"\n",
      "[1] 0.033\n",
      "[1] \"K=  7\"\n",
      "[1] 0.027\n"
     ]
    }
   ],
   "source": [
    "#LOO\n",
    "for (k in ks){\n",
    "    g<-nlevels(set$Species)\n",
    "    C<-matrix(0,nrow=g,ncol=g)\n",
    "    for (i in 1:n){\n",
    "        set.test<-set[i,]\n",
    "        set.train<-set[-i,]\n",
    "        Xtrain<-as.matrix(set.train[,-length(names(set))])\n",
    "        ytrain<-set.train[,length(names(set))]\n",
    "        Xtest<-as.matrix(set.test[,-length(names(set))])\n",
    "        ytest<-set.test[,length(names(set))]\n",
    "        y.hat<-knn(Xtrain,Xtest,ytrain,k)\n",
    "        C[ytest,y.hat]=C[ytest,y.hat]+1\n",
    "    }\n",
    "    print(paste(\"K= \", k))\n",
    "    p.err<-(n-sum(diag(C)))/n\n",
    "    print(round(p.err,3))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"K=  3\"\n",
      " [1] 0.034 0.038 0.077 0.055 0.036 0.017 0.056 0.052 0.016 0.017\n",
      "[1] 0.04\n",
      "[1] \"K=  5\"\n",
      " [1] 0.036 0.056 0.036 0.057 0.018 0.000 0.038 0.035 0.018 0.064\n",
      "[1] 0.036\n",
      "[1] \"K=  7\"\n",
      " [1] 0.017 0.000 0.035 0.017 0.038 0.054 0.075 0.035 0.034 0.021\n",
      "[1] 0.033\n"
     ]
    }
   ],
   "source": [
    "#Boot\n",
    "for (k in ks){\n",
    "    I<-1:n\n",
    "    # Número de remuestras bootstrap\n",
    "    B<-10\n",
    "    P.ERR<-rep(0,B)\n",
    "    for (b in 1:B){\n",
    "        Ib<-sample(I,n,replace = TRUE)\n",
    "        oob<-I[is.na(match(I,Ib))]\n",
    "        Itest<-oob\n",
    "        ntest<-length(oob)\n",
    "        set.test<-set[Itest,]\n",
    "        set.train<-set[-Itest,]\n",
    "        Xtrain<-as.matrix(set.train[,-length(names(set))])\n",
    "        ytrain<-set.train[,length(names(set))]\n",
    "        Xtest<-as.matrix(set.test[,-length(names(set))])\n",
    "        ytest<-set.test[,length(names(set))]\n",
    "        y.hat<-knn(Xtrain,Xtest,ytrain,k)\n",
    "        C<-table(\"True\"=ytest,\"Predicted\"=y.hat)\n",
    "        P.ERR[b]<-(ntest-sum(diag(C)))/ntest\n",
    "    }\n",
    "    print(paste(\"K= \", k))\n",
    "    print(round(P.ERR,3))\n",
    "    mean.p.err<-mean(P.ERR)\n",
    "    print(round(mean.p.err,3))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este caso el mejor valor de \"k\" para el knn en los tres casos es el 5, puesto que 3 y 7 dan mas error en los tres metodos como minimo sabemos que llegamos a un minimo local para el error, pero es bueno porque es mejor que 3 que nos plantearia mas claro el problema de overfitting.\n",
    "\n",
    "Los tres metodos dan unos resultados muy buenos, aunque esto puede deberse a overfitting debido a que hay pocas muestras en el dataset y/o a la poca varianza en los datos.\n",
    "\n",
    "El mejor otra vez es LOO, en este caso tiene mas sentido usarlo debido a la escasa cantidad de muestras. Por el mismo motivo, bootstrap da mejor resultado que el CV pero si hay que escoger uno para este ejemplo escogeriamos el LOO por el bajo error que ha dado y por tener un volumen de datos reducido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Regresion seleccionando por cross-validation un conjunto optimo de predictores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: ISLR\n",
      "Warning message:\n",
      "\"package 'ISLR' was built under R version 3.4.4\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t1250 obs. of  9 variables:\n",
      " $ Year     : num  2001 2001 2001 2001 2001 ...\n",
      " $ Lag1     : num  0.381 0.959 1.032 -0.623 0.614 ...\n",
      " $ Lag2     : num  -0.192 0.381 0.959 1.032 -0.623 ...\n",
      " $ Lag3     : num  -2.624 -0.192 0.381 0.959 1.032 ...\n",
      " $ Lag4     : num  -1.055 -2.624 -0.192 0.381 0.959 ...\n",
      " $ Lag5     : num  5.01 -1.055 -2.624 -0.192 0.381 ...\n",
      " $ Volume   : num  1.19 1.3 1.41 1.28 1.21 ...\n",
      " $ Today    : num  0.959 1.032 -0.623 0.614 0.213 ...\n",
      " $ Direction: Factor w/ 2 levels \"Down\",\"Up\": 2 2 1 2 2 2 1 2 2 2 ...\n"
     ]
    }
   ],
   "source": [
    "require(ISLR)\n",
    "data(Smarket)\n",
    "str(Smarket)\n",
    "\n",
    "set<-Smarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"glm.fit: algorithm did not converge\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: algorithm did not converge\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: algorithm did not converge\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: algorithm did not converge\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: algorithm did not converge\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: algorithm did not converge\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: algorithm did not converge\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: algorithm did not converge\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: algorithm did not converge\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: algorithm did not converge\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: algorithm did not converge\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\""
     ]
    }
   ],
   "source": [
    "set0<-glm(Direction~1,data=set,family=binomial)\n",
    "set1<-glm(Direction~.,data=set,family=binomial)\n",
    "\n",
    "step.result<-step(set0,scope=formula(set1), direction=\"forward\", trace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:  glm(formula = Direction ~ Today, family = binomial, data = set)\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)        Today  \n",
       "      8.421    17192.414  \n",
       "\n",
       "Degrees of Freedom: 1249 Total (i.e. Null);  1248 Residual\n",
       "Null Deviance:\t    1731 \n",
       "Residual Deviance: 0.0007505 \tAIC: 4.001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "step.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Named num [1:1250] 1.00 1.00 2.22e-16 1.00 1.00 ...\n",
      " - attr(*, \"names\")= chr [1:1250] \"1\" \"2\" \"3\" \"4\" ...\n"
     ]
    }
   ],
   "source": [
    "set.pred<-predict(step.result,newdata=set,type=\"response\")\n",
    "str(set.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Predicted\n",
       "True     0   1\n",
       "  Down 602   0\n",
       "  Up     0 648"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.pred.crisp<-1*(set.pred>=0.5)\n",
    "C<-table(\"True\"=set$Direction,\"Predicted\"=set.pred.crisp)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo realizado mas arriba con la funcion step() es una feature selection hacia  adelante (\"forward\").\n",
    "\n",
    "Haria una funcion para hacer feature selection explicitamente con k-fold cross-validation. La funcion haria lo siguiente:\n",
    "\n",
    "- Empezariamos con ninguna variable en el modelo\n",
    "\n",
    "- Usamos el metodo de cross-validation usado en los apartados anteriores, con cada variable del modelo original y cogemos la que tiene la media de error mas baja. Añadimos esa variable al modelo.\n",
    "\n",
    "- Usamos el nuevo modelo + las demas variables; hasta que el error no decrementa o, el decrecimiento es demasiado bajo para que merezca la pena añadirlo al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfoldCV<-function(set,kn,Kf){\n",
    "    n<-nrow(set)\n",
    "    # Fijamos un 'K' para k-fold cross-validation (pongo mayúscula para no confundir con la k de knn)\n",
    "    k<-kn\n",
    "    K<-Kf\n",
    "    J<-kfoldIndexes(n,K)\n",
    "    J\n",
    "    Lower<-J[-(K+1)]\n",
    "    Upper<-J[-1]\n",
    "    Lower\n",
    "    Upper\n",
    "    # Una permutación aleatoria de los índices\n",
    "    I<-sample(1:n)\n",
    "\n",
    "    #cross\n",
    "        P.ERR<-rep(0,K)\n",
    "        for (fold in 1:K){\n",
    "            Itest<-I[Lower[fold]:(Upper[fold]-1)]\n",
    "            set.test<-set[Itest,]\n",
    "            set.train<-set[-Itest,]\n",
    "            Xtrain<-as.matrix(set.train[,-length(names(set))])\n",
    "            ytrain<-set.train[,length(names(set))]\n",
    "            Xtest<-as.matrix(set.test[,-length(names(set))])\n",
    "            ytest<-set.test[,length(names(set))]\n",
    "            y.hat<-knn(Xtrain,Xtest,ytrain,k)\n",
    "            C<-table(\"True\"=ytest,\"Predicted\"=y.hat)\n",
    "            ntest<-sum(C)\n",
    "            P.ERR[fold]<-(ntest-sum(diag(C)))/ntest\n",
    "        }\n",
    "        mean.p.err<-mean(P.ERR)\n",
    "        return(round(mean.p.err,3))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1 2 3 4 5 6 7 8\n",
      "[1] 9\n"
     ]
    }
   ],
   "source": [
    "set<-Smarket\n",
    "\n",
    "features<-c(1:(length(names(set))-1))\n",
    "y<-length(names(set))\n",
    "print(features)\n",
    "print(y)\n",
    "\n",
    "kn<-7\n",
    "Kf<-5\n",
    "featureList<-c(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.001\n",
      "[1] 1 2 3 4 5 6 7\n",
      "[1] 8 9\n",
      "[1] \"Today\"     \"Direction\"\n"
     ]
    }
   ],
   "source": [
    "errors<-c()\n",
    "for(i in features){\n",
    "    columns<-c()\n",
    "    columns<-c(i,featureList)\n",
    "    modelo<-set[columns]\n",
    "    errors<-c(errors, kfoldCV(modelo,kn,Kf))\n",
    "}\n",
    "print(min(errors))\n",
    "indexFound<-match(min(errors),errors)\n",
    "featureList<-c(features[indexFound], featureList)\n",
    "features<-features[-indexFound]\n",
    "print(features)\n",
    "print(featureList)\n",
    "print(names(set[featureList]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No soy muy diestro en R, creo que por eso no se continuar hasta la convergencia de forma automatica, pero el metodo consistiria en seguir ejecutando el programa del recuadro de arriba hasta decidir si estamos contentos con el error que provoca."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
