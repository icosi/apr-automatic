{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification 01 - Linear classification methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Josep Fortiana 2019-10-23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This laboratory is almost entirely devoted to linear classification methods, plus two exceptions, Quadratic discriminant and the $k$-Nearest Neighbours method, at the end of the notebook.\n",
    "\n",
    "Linear methods of classification are those where the assignation criterion is based on values of a linear combination of the predictor variables, or several such combinations when the number $g$ of classes is greater than $2$. \n",
    "\n",
    "Classification methods in general have a geometrical description as a partition of the predictor space (the space whose coordinates are the predictor variables) into two or more regions, one for each class. In linear methods separation is by one or more hyperplanes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Linear classification by least squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle a linear regression by least squares is not an adequate classification method to obtain a hyperplane to separate two classes, or to predict class labels when there are more than two classes.\n",
    "\n",
    "However methodologically unsound it may seem and, as a matter of fact, it is indeed, we can define, in binary classification problems, a numerical response with two conventional values, for instance 0/1, or (-1)/(+1), or in multi-class classification problems, we can define a vector response with as many 0/1 indicator variables as the number $g$ of classes, all of them but one set to $0$, and the remaining one set to $1$, _(one-hot coding),_ fit a linear model in the binary problem, or $g$ parallel linear models in the multi-class problem and then assess the results.\n",
    "\n",
    "Even though results need adaptation or reinterpretation, as regression predicted values are not restricted to the discrete set of values with which the training set has been prepared, often results are surprisingly acceptable, especially when the problem is close to being linearly seeparable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1. `wine` data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`wine` data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines.\n",
    "\n",
    "They can be found in the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/), which hosts many documented data sets to be used as benchmarks in evaluating Machine Learning methods and algorithms. Alternatively, should the link be broken, you can find the `.csv` file in the Virtual Campus. The following description is taken from the UCI website:\n",
    "\n",
    "I think that the initial data set had around 30 variables, but for some reason I only have the 13 dimensional version. I had a list of what the 30 or so variables were, but a.) I lost it, and b.), I would not know which 13 variables are included in the set.\n",
    "\n",
    "The attributes are:\n",
    "\n",
    "01. Alcohol\n",
    "\n",
    "02. Malic acid\n",
    "\n",
    "03. Ash\n",
    "\n",
    "04. Alcalinity of ash\n",
    "\n",
    "05. Magnesium\n",
    "\n",
    "06. Total phenols\n",
    "\n",
    "07. Flavonoids\n",
    "\n",
    "08. Nonflavonoid phenols\n",
    "\n",
    "09. Proanthocyanins\n",
    "\n",
    "10. Color intensity\n",
    "\n",
    "11. Hue\n",
    "\n",
    "12. OD280/OD315 of diluted wines\n",
    "\n",
    "13. Proline\n",
    "\n",
    "\n",
    "In a classification context, this is a well posed problem with \"well behaved\" class structures. A good data set for first testing of a new classifier, but not very challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the `.csv` file has no first row with variable names we must set `header=FALSE` in the `read.csv` call (see default values for the optional parameters in the help). \n",
    "\n",
    "The casting `as.factor()` command has the purpose of conveying the fact that this variable is qualitative, so the R interpreter can use it as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.url<-\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\n",
    "#wine<-read.csv(wine.url,header=FALSE)\n",
    "wine<-read.csv(\"wine.csv\",header=FALSE)\n",
    "colnames(wine)<-c(\"Type\",\"Alcohol\",\"Malic\",\"Ash\", \"Alcalinity\",\"Magnesium\",\"Phenols\",\"Flavonoids\",\n",
    "                  \"Nonflavonoids\",\"Proanthocyanins\",\"Color\",\"Hue\", \"Dilution\",\"Proline\")\n",
    "wine$Type <- as.factor(wine$Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Factor w/ 3 levels \"1\",\"2\",\"3\": 1 1 1 1 1 1 1 1 1 1 ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'1'</li>\n",
       "\t<li>'2'</li>\n",
       "\t<li>'3'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '1'\n",
       "\\item '2'\n",
       "\\item '3'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '1'\n",
       "2. '2'\n",
       "3. '3'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"1\" \"2\" \"3\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  2  3 \n",
       "59 71 48 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "str(wine$Type)\n",
    "levels(wine$Type)\n",
    "table(wine$Type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset in two subsets, for cross-validation, `train` with about $60\\%$ of data, and  `test` with the remaining $\\approx40\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n<-nrow(wine)\n",
    "ntrain<-ceiling(0.6*n)\n",
    "ntest<-n-ntrain\n",
    "set.seed(24025)  # some arbitrary value, for the sake of reproducible results\n",
    "Itrain<-sample(1:n,ntrain,replace=FALSE)\n",
    "wine.train<-wine[Itrain,]\n",
    "wine.test<-wine[-Itrain,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a `Y` vector response with the one-hot coding of the three levels-valued factor response `wine$Type`.\n",
    "\n",
    "Create  `wine2`, a new `data.frame` appending the new three binary variables and discarding the old factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y<-wine$Type\n",
    "Y<-cbind((y==\"1\"),(y==\"2\"),(y==\"3\"))\n",
    "colnames(Y)<-c(\"Y1\",\"Y2\",\"Y3\")\n",
    "wine2<-data.frame(wine[,-1],Y)\n",
    "wine2.train<-wine2[Itrain,]\n",
    "wine2.test<-wine2[-Itrain,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit three parallel linear models with the same set of predictors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response Y1 :\n",
       "\n",
       "Call:\n",
       "lm(formula = Y1 ~ Alcohol + Malic + Ash + Alcalinity + Magnesium + \n",
       "    Phenols + Flavonoids + Nonflavonoids + Proanthocyanins + \n",
       "    Color + Hue + Dilution + Proline, data = wine2.train)\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-0.41580 -0.08969 -0.01396  0.10051  0.35342 \n",
       "\n",
       "Coefficients:\n",
       "                  Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)     -1.704e+00  4.499e-01  -3.788 0.000269 ***\n",
       "Alcohol          7.136e-02  3.362e-02   2.122 0.036453 *  \n",
       "Malic            1.048e-02  1.914e-02   0.548 0.585335    \n",
       "Ash              4.036e-01  8.996e-02   4.486 2.07e-05 ***\n",
       "Alcalinity      -3.682e-02  7.228e-03  -5.094 1.83e-06 ***\n",
       "Magnesium        1.024e-03  1.424e-03   0.719 0.473710    \n",
       "Phenols         -1.507e-01  6.150e-02  -2.451 0.016120 *  \n",
       "Flavonoids       2.167e-01  5.072e-02   4.273 4.66e-05 ***\n",
       "Nonflavonoids    1.843e-01  1.881e-01   0.980 0.329826    \n",
       "Proanthocyanins -2.803e-02  4.328e-02  -0.648 0.518823    \n",
       "Color           -5.030e-03  1.191e-02  -0.422 0.673727    \n",
       "Hue             -1.804e-01  1.102e-01  -1.637 0.104906    \n",
       "Dilution         1.539e-01  4.543e-02   3.388 0.001034 ** \n",
       "Proline          6.166e-04  8.856e-05   6.963 4.64e-10 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.161 on 93 degrees of freedom\n",
       "Multiple R-squared:  0.9016,\tAdjusted R-squared:  0.8878 \n",
       "F-statistic: 65.53 on 13 and 93 DF,  p-value: < 2.2e-16\n",
       "\n",
       "\n",
       "Response Y2 :\n",
       "\n",
       "Call:\n",
       "lm(formula = Y2 ~ Alcohol + Malic + Ash + Alcalinity + Magnesium + \n",
       "    Phenols + Flavonoids + Nonflavonoids + Proanthocyanins + \n",
       "    Color + Hue + Dilution + Proline, data = wine2.train)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-0.4449 -0.1598 -0.0064  0.1275  0.5472 \n",
       "\n",
       "Coefficients:\n",
       "                  Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)      2.8586400  0.6384693   4.477 2.14e-05 ***\n",
       "Alcohol         -0.1210618  0.0477090  -2.538 0.012828 *  \n",
       "Malic           -0.0620164  0.0271611  -2.283 0.024691 *  \n",
       "Ash             -0.4908069  0.1276545  -3.845 0.000221 ***\n",
       "Alcalinity       0.0264749  0.0102565   2.581 0.011407 *  \n",
       "Magnesium        0.0004641  0.0020205   0.230 0.818835    \n",
       "Phenols          0.0006474  0.0872656   0.007 0.994097    \n",
       "Flavonoids       0.1069173  0.0719739   1.486 0.140793    \n",
       "Nonflavonoids    0.3054488  0.2669603   1.144 0.255488    \n",
       "Proanthocyanins  0.0270449  0.0614163   0.440 0.660703    \n",
       "Color           -0.0622212  0.0168986  -3.682 0.000388 ***\n",
       "Hue              0.2597404  0.1563477   1.661 0.100021    \n",
       "Dilution        -0.0231568  0.0644747  -0.359 0.720289    \n",
       "Proline         -0.0005579  0.0001257  -4.439 2.48e-05 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.2285 on 93 degrees of freedom\n",
       "Multiple R-squared:  0.8041,\tAdjusted R-squared:  0.7767 \n",
       "F-statistic: 29.35 on 13 and 93 DF,  p-value: < 2.2e-16\n",
       "\n",
       "\n",
       "Response Y3 :\n",
       "\n",
       "Call:\n",
       "lm(formula = Y3 ~ Alcohol + Malic + Ash + Alcalinity + Magnesium + \n",
       "    Phenols + Flavonoids + Nonflavonoids + Proanthocyanins + \n",
       "    Color + Hue + Dilution + Proline, data = wine2.train)\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-0.41707 -0.07887  0.00008  0.09465  0.32746 \n",
       "\n",
       "Coefficients:\n",
       "                  Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)     -1.543e-01  4.515e-01  -0.342  0.73337    \n",
       "Alcohol          4.970e-02  3.374e-02   1.473  0.14405    \n",
       "Malic            5.154e-02  1.921e-02   2.683  0.00863 ** \n",
       "Ash              8.722e-02  9.027e-02   0.966  0.33640    \n",
       "Alcalinity       1.034e-02  7.253e-03   1.426  0.15725    \n",
       "Magnesium       -1.488e-03  1.429e-03  -1.042  0.30023    \n",
       "Phenols          1.501e-01  6.171e-02   2.432  0.01693 *  \n",
       "Flavonoids      -3.236e-01  5.089e-02  -6.359 7.51e-09 ***\n",
       "Nonflavonoids   -4.897e-01  1.888e-01  -2.594  0.01101 *  \n",
       "Proanthocyanins  9.842e-04  4.343e-02   0.023  0.98197    \n",
       "Color            6.725e-02  1.195e-02   5.628 1.92e-07 ***\n",
       "Hue             -7.933e-02  1.106e-01  -0.718  0.47486    \n",
       "Dilution        -1.308e-01  4.559e-02  -2.868  0.00511 ** \n",
       "Proline         -5.879e-05  8.886e-05  -0.662  0.50986    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.1616 on 93 degrees of freedom\n",
       "Multiple R-squared:  0.8875,\tAdjusted R-squared:  0.8718 \n",
       "F-statistic: 56.44 on 13 and 93 DF,  p-value: < 2.2e-16\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wine2.lm1<-lm(cbind(Y1,Y2,Y3)~.,data=wine2.train)\n",
    "summary(wine2.lm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further analyze the model(s), for instance selecting an optimal predictor subset. This is not so easy as in a single `lm`, as predictors can, and in general do, have different predictive power for each binary response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, `predict.lm()` works here as expected. We prepare the test `data.frame` for prediction, by removing the response columns and keeping them aside for later use in assessing predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine2.test.to.predict<-wine2.test[,-(14:16)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run prediction. Check the structure of the resulting `Yhat`.\n",
    "Indeed `Yhat` is a matrix with 3 columns.\n",
    "\n",
    "Observe that each row in `Yhat` adds up to 1 (Can you explain why?). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num [1:71, 1:3] 1.256 0.65 1.158 0.915 0.921 ...\n",
      " - attr(*, \"dimnames\")=List of 2\n",
      "  ..$ : chr [1:71] \"4\" \"5\" \"8\" \"9\" ...\n",
      "  ..$ : chr [1:3] \"Y1\" \"Y2\" \"Y3\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 1 × 71 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>...</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 1 × 71 of type dbl\n",
       "\\begin{tabular}{lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       "\t 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 1 × 71 of type dbl\n",
       "\n",
       "| 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | ... | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n",
       "[1,] 1    1    1    1    1    1    1    1    1    1     ...   1     1     1    \n",
       "     [,15] [,16] [,17] [,18] [,19] [,20] [,21]\n",
       "[1,] 1     1     1     1     1     1     1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Yhat<-predict(wine2.lm1,newdata=wine2.test.to.predict)\n",
    "str(Yhat)\n",
    "Yhat.sums<-as.numeric(apply(Yhat,1,sum))\n",
    "t(Yhat.sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entries in `Yhat` are not $0$'s or $1$'s as entries in $Y$; they even do not belong to the $(0,1)$ interval, which is a cause of ambiguity in classifications. See the first $5$ rown in `Yhat\n",
    "\n",
    "This is a reason why this method is not a usual one in classification. Anyway we stick to it as an exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 5 × 3 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Y1</th><th scope=col>Y2</th><th scope=col>Y3</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>4</th><td>1.256</td><td>-0.391</td><td>0.135</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.650</td><td> 0.279</td><td>0.071</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>1.158</td><td>-0.181</td><td>0.023</td></tr>\n",
       "\t<tr><th scope=row>9</th><td>0.915</td><td> 0.083</td><td>0.003</td></tr>\n",
       "\t<tr><th scope=row>10</th><td>0.921</td><td> 0.056</td><td>0.023</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 5 × 3 of type dbl\n",
       "\\begin{tabular}{r|lll}\n",
       "  & Y1 & Y2 & Y3\\\\\n",
       "\\hline\n",
       "\t4 & 1.256 & -0.391 & 0.135\\\\\n",
       "\t5 & 0.650 &  0.279 & 0.071\\\\\n",
       "\t8 & 1.158 & -0.181 & 0.023\\\\\n",
       "\t9 & 0.915 &  0.083 & 0.003\\\\\n",
       "\t10 & 0.921 &  0.056 & 0.023\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 5 × 3 of type dbl\n",
       "\n",
       "| <!--/--> | Y1 | Y2 | Y3 |\n",
       "|---|---|---|---|\n",
       "| 4 | 1.256 | -0.391 | 0.135 |\n",
       "| 5 | 0.650 |  0.279 | 0.071 |\n",
       "| 8 | 1.158 | -0.181 | 0.023 |\n",
       "| 9 | 0.915 |  0.083 | 0.003 |\n",
       "| 10 | 0.921 |  0.056 | 0.023 |\n",
       "\n"
      ],
      "text/plain": [
       "   Y1    Y2     Y3   \n",
       "4  1.256 -0.391 0.135\n",
       "5  0.650  0.279 0.071\n",
       "8  1.158 -0.181 0.023\n",
       "9  0.915  0.083 0.003\n",
       "10 0.921  0.056 0.023"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(Yhat[1:5,],3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several possibilities to force `Yhat` into a matrix with a _one-hot_ coding which can be directly read as a classification prediction.\n",
    "\n",
    "What we will do is to assign each individual to the class (column) of the maximum value in the row. \n",
    "\n",
    "We compute the `Yhat.ind` matrix with three columns, which has in each $i$-th row the three indicators, for $j=1,2,3$, of `Yhat[i,j]` equalling the maximum in `Yhat[i,]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yhat.max<-apply(Yhat,1,max)\n",
    "Yhat.ind<-1*cbind(Yhat[,1]==Yhat.max,Yhat[,2]==Yhat.max,Yhat[,3]==Yhat.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "This is a general object in visualizing the quality of a classification algorithm. The _confusion matrix_ for a classification problem with $g$ classes is a matrix $C$ with $g$ rows and $g$ columns.  \n",
    "\n",
    "The classification algorithm is applied to a test data subset in which the true class of each sample is known. In each $i$-th row of $C$ the entry in the $j$-th column is the number of samples whose true class is $i$ which the algorithm has assigned to the $j$-th class. \n",
    "\n",
    "A perfect classification would yield a diagonal confusion matrix (with non-null entris oly on the principal diagonal). \n",
    "\n",
    "Measures of quality can be derived from the proportion of off-diagonal entries, either row-wise or globally. For instance the sum of all off-diagonal entries divided by the total sample size is an estimate of the probability of misclassification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A computation of the confusion matrix by means of a matrix product. (NB: possible here because both `Y`and `Yhat` are three column matrices with zeros and ones!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 3 × 3 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>1</th><th scope=col>2</th><th scope=col>3</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>21</td><td> 0</td><td> 0</td></tr>\n",
       "\t<tr><td> 1</td><td>31</td><td> 0</td></tr>\n",
       "\t<tr><td> 0</td><td> 0</td><td>18</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 3 × 3 of type dbl\n",
       "\\begin{tabular}{r|lll}\n",
       " 1 & 2 & 3\\\\\n",
       "\\hline\n",
       "\t 21 &  0 &  0\\\\\n",
       "\t  1 & 31 &  0\\\\\n",
       "\t  0 &  0 & 18\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 3 × 3 of type dbl\n",
       "\n",
       "| 1 | 2 | 3 |\n",
       "|---|---|---|\n",
       "| 21 |  0 |  0 |\n",
       "|  1 | 31 |  0 |\n",
       "|  0 |  0 | 18 |\n",
       "\n"
      ],
      "text/plain": [
       "    Predicted\n",
       "True 1  2  3 \n",
       "   1 21  0  0\n",
       "   2  1 31  0\n",
       "   3  0  0 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y.test<-Y[-Itrain,]\n",
    "C<-t(Y.test)%*%Yhat.ind\n",
    "dimnames(C)<-list(True=c(1,2,3),Predicted=c(1,2,3))\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another procedure which, by the way, is more generalizable to other classification methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Predicted\n",
       "True  1  2  3\n",
       "   1 21  0  0\n",
       "   2  1 31  0\n",
       "   3  0  0 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.test<-y[-Itrain]\n",
    "yhat<-as.factor(apply(Yhat,1,which.max))\n",
    "C<-table(\"True\"=y.test,\"Predicted\"=yhat)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Linear classification by logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in the theory slides, logistic regression is a statistical model, an instance of a Generalized Linear Model (GLM) which is usually fitted by Maximum Likelihood.\n",
    "\n",
    "Its R implementation is in the `glm()` function from the `stats` package (loaded by default). Syntax is similar to that of `lm()`. See details in the help, which you can invoke by typing `?glm`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B1. `SAheart` data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `ElemStatLearn` package, `SAheart` is a data frame with 462 observations on the following 10 variables.\n",
    "\n",
    "01. `sbp`: systolic blood pressure.\n",
    "\n",
    "02. `tobacco`: cumulative tobacco (kg).\n",
    "\n",
    "03. `ldl`: low density lipoprotein cholesterol.\n",
    "\n",
    "04. `adiposity`: a numeric vector.\n",
    "\n",
    "05. `famhist`: family history of heart disease, a factor with levels `Absent`, `Present`.\n",
    "\n",
    "06. `typea`: type-A behavior.\n",
    "\n",
    "07. `obesity`: a numeric vector.\n",
    "\n",
    "08. `alcohol`: current alcohol consumption.\n",
    "\n",
    "09. `age`: age at onset\n",
    "\n",
    "10. `chd`: response, coronary heart disease\n",
    "\n",
    "##### Details\n",
    "\n",
    "A retrospective sample of males in a heart-disease high-risk region of the Western Cape, South Africa. There are roughly two controls per case of CHD. Many of the CHD positive men have undergone blood pressure reduction treatment and other programs to reduce their risk factors after their CHD event. In some cases the measurements were made after these treatments. These data are taken from a larger dataset, described in Rousseauw et al, 1983, South African Medical Journal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: ElemStatLearn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t462 obs. of  10 variables:\n",
      " $ sbp      : int  160 144 118 170 134 132 142 114 114 132 ...\n",
      " $ tobacco  : num  12 0.01 0.08 7.5 13.6 6.2 4.05 4.08 0 0 ...\n",
      " $ ldl      : num  5.73 4.41 3.48 6.41 3.5 6.47 3.38 4.59 3.83 5.8 ...\n",
      " $ adiposity: num  23.1 28.6 32.3 38 27.8 ...\n",
      " $ famhist  : Factor w/ 2 levels \"Absent\",\"Present\": 2 1 2 2 2 2 1 2 2 2 ...\n",
      " $ typea    : int  49 55 52 51 60 62 59 62 49 69 ...\n",
      " $ obesity  : num  25.3 28.9 29.1 32 26 ...\n",
      " $ alcohol  : num  97.2 2.06 3.81 24.26 57.34 ...\n",
      " $ age      : int  52 63 46 58 49 45 38 58 29 53 ...\n",
      " $ chd      : int  1 1 0 1 1 0 0 1 0 1 ...\n"
     ]
    }
   ],
   "source": [
    "#install.packages(\"ElemStatLearn\",dependencies=TRUE,repos=\"https://cloud.r-project.org\")\n",
    "require(ElemStatLearn)\n",
    "data(SAheart)\n",
    "str(SAheart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response `chd` is coded as an integer-valued variable with $0/1$ values. For some classification procedures we should recode it as a factor with two levels, as we did with the `wine` data. Logistic regression does not require this step, as it will process correctly with the current coding. However keep in mind this feature before applying other classification methods  on this dataset (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into a pair $(\\text{train},\\text{test})$ of subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(24025)\n",
    "n<-nrow(SAheart)\n",
    "ntrain<-ceiling(0.60*n)\n",
    "Itrain<-sample(1:n,ntrain,replace=FALSE)\n",
    "n<-nrow(SAheart)\n",
    "ntrain<-ceiling(0.60*n)\n",
    "Itrain<-sample(1:n,ntrain,replace=FALSE)\n",
    "SAheart.train<-SAheart[Itrain,]\n",
    "SAheart.test<-SAheart[-Itrain,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying logistic regression, we can try to classify `SAheart` data by the least squares method and estimate the misclassification probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syntax for `glm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAheart.logit1<-glm(chd~.,data=SAheart.train,family=binomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = chd ~ ., family = binomial, data = SAheart.train)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.1308  -0.7738  -0.4384   0.8366   2.2841  \n",
       "\n",
       "Coefficients:\n",
       "                Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)    -7.252428   1.769751  -4.098 4.17e-05 ***\n",
       "sbp             0.008629   0.007979   1.082  0.27947    \n",
       "tobacco         0.111020   0.035591   3.119  0.00181 ** \n",
       "ldl             0.263452   0.084697   3.111  0.00187 ** \n",
       "adiposity      -0.015090   0.037507  -0.402  0.68744    \n",
       "famhistPresent  0.830130   0.301427   2.754  0.00589 ** \n",
       "typea           0.032812   0.016411   1.999  0.04557 *  \n",
       "obesity         0.004643   0.055596   0.084  0.93344    \n",
       "alcohol        -0.007579   0.006766  -1.120  0.26264    \n",
       "age             0.046532   0.015339   3.033  0.00242 ** \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 368.59  on 277  degrees of freedom\n",
       "Residual deviance: 280.94  on 268  degrees of freedom\n",
       "AIC: 300.94\n",
       "\n",
       "Number of Fisher Scoring iterations: 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(SAheart.logit1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary of `glm()` is similar to that of `lm()`, including the $p$-values giving some indication about the coefficients significance.\n",
    "\n",
    "The (Residual) `Deviance` is a quantity equivalent to the Residual Sum of Squares in a `lm()`.\n",
    "\n",
    "Another consequence of the fact that `glm()` fits a statistical model is the possibility of predictor selection by means of a `step()` functions just as in `lm()`. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:  AIC=300.94\n",
      "chd ~ sbp + tobacco + ldl + adiposity + famhist + typea + obesity + \n",
      "    alcohol + age\n",
      "\n",
      "            Df Deviance    AIC\n",
      "- obesity    1   280.95 298.95\n",
      "- adiposity  1   281.10 299.10\n",
      "- sbp        1   282.12 300.12\n",
      "- alcohol    1   282.25 300.25\n",
      "<none>           280.94 300.94\n",
      "- typea      1   285.11 303.11\n",
      "- famhist    1   288.59 306.59\n",
      "- age        1   290.52 308.52\n",
      "- ldl        1   291.40 309.40\n",
      "- tobacco    1   291.92 309.92\n",
      "\n",
      "Step:  AIC=298.95\n",
      "chd ~ sbp + tobacco + ldl + adiposity + famhist + typea + alcohol + \n",
      "    age\n",
      "\n",
      "            Df Deviance    AIC\n",
      "- adiposity  1   281.22 297.22\n",
      "- sbp        1   282.13 298.13\n",
      "- alcohol    1   282.29 298.29\n",
      "<none>           280.95 298.95\n",
      "- typea      1   285.29 301.29\n",
      "- famhist    1   288.59 304.59\n",
      "- ldl        1   291.42 307.42\n",
      "- age        1   291.47 307.47\n",
      "- tobacco    1   291.92 307.92\n",
      "\n",
      "Step:  AIC=297.22\n",
      "chd ~ sbp + tobacco + ldl + famhist + typea + alcohol + age\n",
      "\n",
      "          Df Deviance    AIC\n",
      "- sbp      1   282.24 296.24\n",
      "- alcohol  1   282.67 296.67\n",
      "<none>         281.22 297.22\n",
      "- typea    1   285.57 299.57\n",
      "- famhist  1   288.87 302.87\n",
      "- ldl      1   291.82 305.82\n",
      "- age      1   292.09 306.09\n",
      "- tobacco  1   292.18 306.18\n",
      "\n",
      "Step:  AIC=296.24\n",
      "chd ~ tobacco + ldl + famhist + typea + alcohol + age\n",
      "\n",
      "          Df Deviance    AIC\n",
      "- alcohol  1   283.27 295.27\n",
      "<none>         282.24 296.24\n",
      "- typea    1   286.24 298.24\n",
      "- famhist  1   289.45 301.45\n",
      "- tobacco  1   292.67 304.67\n",
      "- ldl      1   293.25 305.25\n",
      "- age      1   296.00 308.00\n",
      "\n",
      "Step:  AIC=295.27\n",
      "chd ~ tobacco + ldl + famhist + typea + age\n",
      "\n",
      "          Df Deviance    AIC\n",
      "<none>         283.27 295.27\n",
      "- typea    1   287.39 297.39\n",
      "- famhist  1   290.63 300.63\n",
      "- tobacco  1   292.85 302.85\n",
      "- ldl      1   295.66 305.66\n",
      "- age      1   296.72 306.72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:  glm(formula = chd ~ tobacco + ldl + famhist + typea + age, family = binomial, \n",
       "    data = SAheart.train)\n",
       "\n",
       "Coefficients:\n",
       "   (Intercept)         tobacco             ldl  famhistPresent           typea  \n",
       "      -6.35777         0.10012         0.26250         0.80533         0.03191  \n",
       "           age  \n",
       "       0.04651  \n",
       "\n",
       "Degrees of Freedom: 277 Total (i.e. Null);  272 Residual\n",
       "Null Deviance:\t    368.6 \n",
       "Residual Deviance: 283.3 \tAIC: 295.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "step(SAheart.logit1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selects a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.model<-chd ~ tobacco + ldl + famhist + typea + age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `sbp`, `adiposity`, `obesity`, `alcohol` have been removed from the list of predictors. We can fit the selected model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = sel.model, family = binomial, data = SAheart.train)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.0396  -0.7822  -0.4256   0.8711   2.2811  \n",
       "\n",
       "Coefficients:\n",
       "               Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)    -6.35777    1.18171  -5.380 7.44e-08 ***\n",
       "tobacco         0.10012    0.03415   2.932 0.003371 ** \n",
       "ldl             0.26250    0.07817   3.358 0.000786 ***\n",
       "famhistPresent  0.80533    0.29788   2.704 0.006860 ** \n",
       "typea           0.03191    0.01605   1.989 0.046731 *  \n",
       "age             0.04651    0.01315   3.537 0.000405 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 368.59  on 277  degrees of freedom\n",
       "Residual deviance: 283.27  on 272  degrees of freedom\n",
       "AIC: 295.27\n",
       "\n",
       "Number of Fisher Scoring iterations: 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SAheart.logit2<-glm(sel.model,data=SAheart.train,family=binomial)\n",
    "summary(SAheart.logit2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syntax of `predict.glm()` to compute probabilities of belonging to each class.\n",
    "\n",
    "Actually probabilities of the binary $0/1$  response taking the value $1$ (here `chd=1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Named num [1:184] 0.7154 0.1955 0.5264 0.0265 0.1821 ...\n",
      " - attr(*, \"names\")= chr [1:184] \"5\" \"7\" \"11\" \"14\" ...\n"
     ]
    }
   ],
   "source": [
    "SAheart.pred<-predict(SAheart.logit2,newdata=SAheart.test[,c(2,3,5,6,9)],type=\"response\")\n",
    "str(SAheart.pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a _crisp_ assignation to `0` or `1` is required, one has to decide a cut point, for instance $L=0.5$ (this value is not mandatory, it can depend on the model or on the _a priori_ probabilities) and classify as $0$ or $1$ depending on whether the probability is higher or lower than this threshold:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for this classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Predicted\n",
       "True  0  1\n",
       "   0 99 30\n",
       "   1 28 27"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SAheart.pred.crisp<-1*(SAheart.pred>=0.5)\n",
    "C<-table(\"True\"=SAheart.test$chd,\"Predicted\"=SAheart.pred.crisp)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some internal details about computations in logistic regression\n",
    "\n",
    "In the slides `Detalles.Reg.Logistica.slides.esp.pdf` you can find an explanation of the logistic regression model and of the numerical procedure used to obtain the maximum likelihood estimates of the model coefficients. \n",
    "\n",
    "It is a variant of the Newton-Raphson optimization method, which results in an iterative computation by successive approximations,  where each step is equivalent to a Weighted Least Squares fit, with the weight for each sample is updated for each step. The procedure is called IWLS or IRLS, meaning Iteratively (Re)Weighted Least Squares. \n",
    "\n",
    "In the `IWLS.r` script you can see a simple implementation of this algorithm.\n",
    "\n",
    "The `separation.txt` data shows a case of non-existence of a Maximum Likelihood estimate for the logistic regression models. Try these data with the `IWLS()`  function in `IWLS.r` and with the `glm()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B2. `Default` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `ISLR` package. A simulated data set containing information on ten thousand customers. The aim here is to predict which customers will default on their credit card debt.\n",
    "\n",
    "A data frame with 10000 observations on the following 4 variables.\n",
    "\n",
    "01. `default`: A factor with levels `No` and `Yes` indicating whether the customer defaulted on their debt\n",
    "\n",
    "02. `student`: A factor with levels `No` and `Yes` indicating whether the customer is a student\n",
    "\n",
    "03. `balance`: The average balance that the customer has remaining on their credit card after making their monthly payment\n",
    "\n",
    "04. `income`: Income of customer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: ISLR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t10000 obs. of  4 variables:\n",
      " $ default: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ student: Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 2 1 1 ...\n",
      " $ balance: num  730 817 1074 529 786 ...\n",
      " $ income : num  44362 12106 31767 35704 38463 ...\n"
     ]
    }
   ],
   "source": [
    "#install.packages(\"ISLR\",dependencies=TRUE,repos=\"https://cloud.r-project.org\")\n",
    "require(ISLR)\n",
    "data(Default)\n",
    "str(Default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = default ~ balance, family = binomial, data = Default)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.2697  -0.1465  -0.0589  -0.0221   3.7589  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -1.065e+01  3.612e-01  -29.49   <2e-16 ***\n",
       "balance      5.499e-03  2.204e-04   24.95   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 2920.6  on 9999  degrees of freedom\n",
       "Residual deviance: 1596.5  on 9998  degrees of freedom\n",
       "AIC: 1600.5\n",
       "\n",
       "Number of Fisher Scoring iterations: 8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>-10.6513</dd>\n",
       "\t<dt>balance</dt>\n",
       "\t\t<dd>0.0055</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] -10.6513\n",
       "\\item[balance] 0.0055\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   -10.6513balance\n",
       ":   0.0055\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)     balance \n",
       "   -10.6513      0.0055 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Default.logit1<-glm(default~balance,family=binomial,data=Default)\n",
    "summary(Default.logit1)\n",
    "round(coefficients(Default.logit1),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making prediction for new cases\n",
    "\n",
    "The output of `predict()`is to be interpreted as a probability of `Default=Yes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>1:</strong> 0.00575"
      ],
      "text/latex": [
       "\\textbf{1:} 0.00575"
      ],
      "text/markdown": [
       "**1:** 0.00575"
      ],
      "text/plain": [
       "      1 \n",
       "0.00575 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(predict(Default.logit1,newdata=data.frame(balance=1000),type=\"response\"),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A larger balance makes default more likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>1:</strong> 0.58577"
      ],
      "text/latex": [
       "\\textbf{1:} 0.58577"
      ],
      "text/markdown": [
       "**1:** 0.58577"
      ],
      "text/plain": [
       "      1 \n",
       "0.58577 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(predict(Default.logit1,newdata=data.frame(balance=2000),type=\"response\"),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression with a categorical predictor:  `student`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = default ~ student, family = binomial, data = Default)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-0.2970  -0.2970  -0.2434  -0.2434   2.6585  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -3.50413    0.07071  -49.55  < 2e-16 ***\n",
       "studentYes   0.40489    0.11502    3.52 0.000431 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 2920.6  on 9999  degrees of freedom\n",
       "Residual deviance: 2908.7  on 9998  degrees of freedom\n",
       "AIC: 2912.7\n",
       "\n",
       "Number of Fisher Scoring iterations: 6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>-3.5041</dd>\n",
       "\t<dt>studentYes</dt>\n",
       "\t\t<dd>0.4049</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] -3.5041\n",
       "\\item[studentYes] 0.4049\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   -3.5041studentYes\n",
       ":   0.4049\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  studentYes \n",
       "    -3.5041      0.4049 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Default.logit2<-glm(default~student,family=binomial,data=Default)\n",
    "summary(Default.logit2)\n",
    "round(coefficients(Default.logit2),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 6 × 2 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>(Intercept)</th><th scope=col>studentYes</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>1</td></tr>\n",
       "\t<tr><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 6 × 2 of type dbl\n",
       "\\begin{tabular}{r|ll}\n",
       " (Intercept) & studentYes\\\\\n",
       "\\hline\n",
       "\t 1 & 0\\\\\n",
       "\t 1 & 1\\\\\n",
       "\t 1 & 0\\\\\n",
       "\t 1 & 0\\\\\n",
       "\t 1 & 0\\\\\n",
       "\t 1 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 6 × 2 of type dbl\n",
       "\n",
       "| (Intercept) | studentYes |\n",
       "|---|---|\n",
       "| 1 | 0 |\n",
       "| 1 | 1 |\n",
       "| 1 | 0 |\n",
       "| 1 | 0 |\n",
       "| 1 | 0 |\n",
       "| 1 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "  (Intercept) studentYes\n",
       "1 1           0         \n",
       "2 1           1         \n",
       "3 1           0         \n",
       "4 1           0         \n",
       "5 1           0         \n",
       "6 1           1         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(model.matrix(Default.logit2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression with several predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = default ~ ., family = binomial, data = Default)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.4691  -0.1418  -0.0557  -0.0203   3.7383  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -1.087e+01  4.923e-01 -22.080  < 2e-16 ***\n",
       "studentYes  -6.468e-01  2.363e-01  -2.738  0.00619 ** \n",
       "balance      5.737e-03  2.319e-04  24.738  < 2e-16 ***\n",
       "income       3.033e-06  8.203e-06   0.370  0.71152    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 2920.6  on 9999  degrees of freedom\n",
       "Residual deviance: 1571.5  on 9996  degrees of freedom\n",
       "AIC: 1579.5\n",
       "\n",
       "Number of Fisher Scoring iterations: 8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Default.logit3<-glm(default~.,family=binomial,data=Default)\n",
    "summary(Default.logit3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `step()` to select an optimal predictor subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:  AIC=1579.54\n",
      "default ~ student + balance + income\n",
      "\n",
      "          Df Deviance    AIC\n",
      "- income   1   1571.7 1577.7\n",
      "<none>         1571.5 1579.5\n",
      "- student  1   1579.0 1585.0\n",
      "- balance  1   2907.5 2913.5\n",
      "\n",
      "Step:  AIC=1577.68\n",
      "default ~ student + balance\n",
      "\n",
      "          Df Deviance    AIC\n",
      "<none>         1571.7 1577.7\n",
      "- student  1   1596.5 1600.5\n",
      "- balance  1   2908.7 2912.7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:  glm(formula = default ~ student + balance, family = binomial, \n",
       "    data = Default)\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)   studentYes      balance  \n",
       " -10.749496    -0.714878     0.005738  \n",
       "\n",
       "Degrees of Freedom: 9999 Total (i.e. Null);  9997 Residual\n",
       "Null Deviance:\t    2921 \n",
       "Residual Deviance: 1572 \tAIC: 1578"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "step(Default.logit3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Fisher linear discriminant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fisher's discriminant is the oldest method of classification from several predictor variables. It was introduced by Ronald A. Fisher (1936) _\"The Use of Multiple Measurements in Taxonomic Problems\"._ Also this article features, as an illustration, the famous _Iris flowers_ dataset for a problem of classification into three classes, _\"Iris setosa\",_ _\"Iris virginica\",_ and _\"Iris versicolor\",_ from four numerical variables, _\"Sepal width\",_ _\"Sepal length\",_ _\"Petal width\",_ _\"Petal length\"._\n",
    "\n",
    "As with all linear discriminant methods, it is more successful when the distribution of data in the predictor space is given by a mixture of Gaussian (multivariate normal) distributions. Geometrically when the set of individuals-points in each class  has an ellipsoidal shape around its centroid, its mean. Actually a probabilistic derivation of Fisher discriminant functions\n",
    "assumes classes modelled by Gaussian distributions with a common matrix of variances and covariances (shortly covariances matrix). There is a purely geometrical derivation in terms of distances between individuals. A nice visual explanation can be found in the blog entry [An illustrative introduction to Fisher's Linear Discriminant](https://sthalles.github.io/fisher-linear-discriminant/).\n",
    "\n",
    "Among the many implementations of Fisher's linear discriminant we can use the `lda` function is the `MASS` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C1. `Iris` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default `datasets` package in the standard R distribution contains this dataset in two formats: `iris` and `iris3`. We use here the first version, a `data.frame` with the five variables:\n",
    "\n",
    " 01. `Sepal.Length`: Continuous numerical. \n",
    " 02. `Sepal.Width`: Continuous numerical. \n",
    " 03. `Petal.Length`: Continuous numerical. \n",
    " 04. `Petal.Width`: Continuous numerical. \n",
    " 05. `Species`: Factor with three levels: `'setosa'` `'versicolor'` `'virginica'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t150 obs. of  5 variables:\n",
      " $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n",
      " $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n",
      " $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n",
      " $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n",
      " $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'setosa'</li>\n",
       "\t<li>'versicolor'</li>\n",
       "\t<li>'virginica'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'setosa'\n",
       "\\item 'versicolor'\n",
       "\\item 'virginica'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'setosa'\n",
       "2. 'versicolor'\n",
       "3. 'virginica'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"setosa\"     \"versicolor\" \"virginica\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "    setosa versicolor  virginica \n",
       "        50         50         50 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data(iris)\n",
    "str(iris)\n",
    "levels(iris$Species)\n",
    "table(iris$Species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare two subsets for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n<-nrow(iris)\n",
    "ntrain<-ceiling(0.6*n)\n",
    "set.seed(24025)         # An arbitrary value, fixed for the sake of reproducibility of results\n",
    "Itrain<-sample(1:n,ntrain,replace=FALSE)\n",
    "iris.train<-iris[Itrain,]\n",
    "iris.test<-iris[-Itrain,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the linear discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: MASS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            Predicted\n",
       "True         setosa versicolor virginica\n",
       "  setosa         19          0         0\n",
       "  versicolor      0         18         1\n",
       "  virginica       0          0        22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "require(MASS)\n",
    "iris.lda<-lda(Species~.,data=iris.train)\n",
    "iris.pred<-predict(iris.lda,newdata=iris.test)\n",
    "C<-table(\"True\"=iris.test$Species,\"Predicted\"=iris.pred$class)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a `plot.lda` method for objects of class `lda` (the output of the `lda()` function). See the help file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAMAAACJuGjuAAAANlBMVEUAAAAAAP9NTU1oaGh8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\nEBYkCAsShAUJwoIEYUGCsCDxP3eSQsSgHBsoAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width=5, repr.plot.height=5)\n",
    "plot(iris.lda,cex=0.6,col=c(\"red\",\"blue\",\"black\"),abbrev=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an `ldahist` function, to visualize distributions of individual predictor variables across groups. It can plot either histograms, or density estimates (kernel smoothing, see the help of the R `density` function), or both. Some trial and error fine tuning of optional parameters is advisable. For instance when plotting density estimates, it may happen that the bandwidth smoothing parameter `width` default value computation crashes and it must be set by hand. Other graphical parameters are difficult (or impossible, I don't know which) to set, hence this function has a limited usefulness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAJYCAMAAACNe8UiAAAACVBMVEUAAAAA//////+XvA6v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\nhjMwnIHhDAz3P4JCh+iP1igRAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width=4, repr.plot.height=5)\n",
    "ldahist(iris$Sepal.Length,iris$Species,type=\"histogram\")  # this is the default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAJYCAMAAACNe8UiAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nOBQMDgWDQ8HgUDA4FAzOP9B227A+FuBHAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ldahist(iris$Sepal.Length,iris$Species,type=\"density\",lwd=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAJYCAMAAACNe8UiAAAACVBMVEUAAAAAAP////9d2Mkj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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ldahist(iris$Sepal.Length,iris$Species,type=\"both\",lwd=2,col=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAJYCAMAAACNe8UiAAAACVBMVEUAAAAA//////+XvA6v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\nwxMYnsDwBIYnMDyB4QkMT2B4AsP7D2KngIzNT4XCAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ldahist(iris$Sepal.Width,iris$Species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAJYCAMAAACNe8UiAAAACVBMVEUAAAAA//////+XvA6v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\nhvsPaMSbYXrJ91QAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ldahist(iris$Petal.Length,iris$Species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAJYCAMAAACNe8UiAAAACVBMVEUAAAAA//////+XvA6v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\nhjMwnIHhDAz3H7UdmB9hhhuVAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ldahist(iris$Petal.Width,iris$Species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Built-in _leave-one-out_ cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            LOO Predicted\n",
       "True         setosa versicolor virginica\n",
       "  setosa         50          0         0\n",
       "  versicolor      0         48         2\n",
       "  virginica       0          1        49"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris.lda.CV<-lda(Species~.,data=iris, CV=TRUE)\n",
    "#str(iris.lda.CV)\n",
    "C<-table(\"True\"=iris$Species,\"LOO Predicted\"=iris.lda.CV$class)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C2. `SAheart` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw above, originally the response variable `chd` is numerically coded with $0/1$ values. This is not an obstacle for logistic regression or with `lda`. For some other methods, it will be an issue. For instance the Clasification and Regression Trees function `rpart()` requires the response variable in a classification to be a factor, otherwise it will perform a regression.\n",
    "\n",
    "Similarly,  the `glm()` function we use to fit logistic regression, is capable of dealing with qualitative predictor variables, by constructing a design matrix with the appropriate indicator variables. In this dataset, one of the risk factors, `famhist`, appears as a factor with two levels. It might be necessary to recode it either as a numeric variable or to obtain the `model.matrix` by a dummy call to `lm()`or `glm()`.\n",
    "\n",
    "In any case to be on the safe side, better check capabilities of any given function before blindly using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAheart.lda1<-lda(chd~.,data=SAheart.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Predicted\n",
       "True  0  1\n",
       "   0 97 32\n",
       "   1 27 28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SAheart.pred<-predict(SAheart.lda1,newdata=SAheart.test)\n",
    "C<-table(\"True\"=SAheart.test$chd,\"Predicted\"=SAheart.pred$class)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Quadratic discriminant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quadratic discriminant can be considered as an slight extension of Fisher's linear discriminant. Thus it is reasonable to study it here even though it is not linear. It has a probabilistic derivation like that of Fisher's LD, relaxing the assumption that groups are modelled as Gaussians with a common covariances matrix to Gaussians, each with its own covariances matrix.\n",
    "\n",
    "Implemented in the `qda()` function, `MASS` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D1. `SAheart` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Predicted\n",
       "True   0   1\n",
       "   0 102  27\n",
       "   1  28  27"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SAheart.qda1<-qda(chd~.,data=SAheart.train)\n",
    "SAheart.pred<-predict(SAheart.qda1,newdata=SAheart.test)\n",
    "C<-table(\"True\"=SAheart.test$chd,\"Predicted\"=SAheart.pred$class)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D2. `Smarket` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an S&P Stock Market Data set. Daily percentage returns for the S&P 500 stock index between 2001 and 2005.\n",
    "Contained in the `ISLR` package as a `data.frame` with 1250 observations on the following 9 variables.\n",
    "\n",
    "01. `Year`: The year that the observation was recorded\n",
    "\n",
    "02. `Lag1`: Percentage return for previous day\n",
    "\n",
    "03. `Lag2`: Percentage return for 2 days previous\n",
    "\n",
    "04. `Lag3`: Percentage return for 3 days previous\n",
    "\n",
    "05. `Lag4`: Percentage return for 4 days previous\n",
    "\n",
    "06. `Lag5`: Percentage return for 5 days previous\n",
    "\n",
    "07. `Volume`: Volume of shares traded (number of daily shares traded in billions)\n",
    "\n",
    "08. `Today`: Percentage return for today\n",
    "\n",
    "09. `Direction`: A factor with levels `Down` and `Up` indicating whether the market had a positive or negative return on a given day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t1250 obs. of  9 variables:\n",
      " $ Year     : num  2001 2001 2001 2001 2001 ...\n",
      " $ Lag1     : num  0.381 0.959 1.032 -0.623 0.614 ...\n",
      " $ Lag2     : num  -0.192 0.381 0.959 1.032 -0.623 ...\n",
      " $ Lag3     : num  -2.624 -0.192 0.381 0.959 1.032 ...\n",
      " $ Lag4     : num  -1.055 -2.624 -0.192 0.381 0.959 ...\n",
      " $ Lag5     : num  5.01 -1.055 -2.624 -0.192 0.381 ...\n",
      " $ Volume   : num  1.19 1.3 1.41 1.28 1.21 ...\n",
      " $ Today    : num  0.959 1.032 -0.623 0.614 0.213 ...\n",
      " $ Direction: Factor w/ 2 levels \"Down\",\"Up\": 2 2 1 2 2 2 1 2 2 2 ...\n"
     ]
    }
   ],
   "source": [
    "require(ISLR)\n",
    "data(Smarket)\n",
    "str(Smarket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Year           Lag1                Lag2                Lag3          \n",
       " Min.   :2001   Min.   :-4.922000   Min.   :-4.922000   Min.   :-4.922000  \n",
       " 1st Qu.:2002   1st Qu.:-0.639500   1st Qu.:-0.639500   1st Qu.:-0.640000  \n",
       " Median :2003   Median : 0.039000   Median : 0.039000   Median : 0.038500  \n",
       " Mean   :2003   Mean   : 0.003834   Mean   : 0.003919   Mean   : 0.001716  \n",
       " 3rd Qu.:2004   3rd Qu.: 0.596750   3rd Qu.: 0.596750   3rd Qu.: 0.596750  \n",
       " Max.   :2005   Max.   : 5.733000   Max.   : 5.733000   Max.   : 5.733000  \n",
       "      Lag4                Lag5              Volume           Today          \n",
       " Min.   :-4.922000   Min.   :-4.92200   Min.   :0.3561   Min.   :-4.922000  \n",
       " 1st Qu.:-0.640000   1st Qu.:-0.64000   1st Qu.:1.2574   1st Qu.:-0.639500  \n",
       " Median : 0.038500   Median : 0.03850   Median :1.4229   Median : 0.038500  \n",
       " Mean   : 0.001636   Mean   : 0.00561   Mean   :1.4783   Mean   : 0.003138  \n",
       " 3rd Qu.: 0.596750   3rd Qu.: 0.59700   3rd Qu.:1.6417   3rd Qu.: 0.596750  \n",
       " Max.   : 5.733000   Max.   : 5.73300   Max.   :3.1525   Max.   : 5.733000  \n",
       " Direction \n",
       " Down:602  \n",
       " Up  :648  \n",
       "           \n",
       "           \n",
       "           \n",
       "           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(Smarket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 8 × 8 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Year</th><th scope=col>Lag1</th><th scope=col>Lag2</th><th scope=col>Lag3</th><th scope=col>Lag4</th><th scope=col>Lag5</th><th scope=col>Volume</th><th scope=col>Today</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Year</th><td>1.00</td><td> 0.03</td><td> 0.03</td><td> 0.03</td><td> 0.04</td><td> 0.03</td><td> 0.54</td><td> 0.03</td></tr>\n",
       "\t<tr><th scope=row>Lag1</th><td>0.03</td><td> 1.00</td><td>-0.03</td><td>-0.01</td><td> 0.00</td><td>-0.01</td><td> 0.04</td><td>-0.03</td></tr>\n",
       "\t<tr><th scope=row>Lag2</th><td>0.03</td><td>-0.03</td><td> 1.00</td><td>-0.03</td><td>-0.01</td><td> 0.00</td><td>-0.04</td><td>-0.01</td></tr>\n",
       "\t<tr><th scope=row>Lag3</th><td>0.03</td><td>-0.01</td><td>-0.03</td><td> 1.00</td><td>-0.02</td><td>-0.02</td><td>-0.04</td><td> 0.00</td></tr>\n",
       "\t<tr><th scope=row>Lag4</th><td>0.04</td><td> 0.00</td><td>-0.01</td><td>-0.02</td><td> 1.00</td><td>-0.03</td><td>-0.05</td><td>-0.01</td></tr>\n",
       "\t<tr><th scope=row>Lag5</th><td>0.03</td><td>-0.01</td><td> 0.00</td><td>-0.02</td><td>-0.03</td><td> 1.00</td><td>-0.02</td><td>-0.03</td></tr>\n",
       "\t<tr><th scope=row>Volume</th><td>0.54</td><td> 0.04</td><td>-0.04</td><td>-0.04</td><td>-0.05</td><td>-0.02</td><td> 1.00</td><td> 0.01</td></tr>\n",
       "\t<tr><th scope=row>Today</th><td>0.03</td><td>-0.03</td><td>-0.01</td><td> 0.00</td><td>-0.01</td><td>-0.03</td><td> 0.01</td><td> 1.00</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 8 × 8 of type dbl\n",
       "\\begin{tabular}{r|llllllll}\n",
       "  & Year & Lag1 & Lag2 & Lag3 & Lag4 & Lag5 & Volume & Today\\\\\n",
       "\\hline\n",
       "\tYear & 1.00 &  0.03 &  0.03 &  0.03 &  0.04 &  0.03 &  0.54 &  0.03\\\\\n",
       "\tLag1 & 0.03 &  1.00 & -0.03 & -0.01 &  0.00 & -0.01 &  0.04 & -0.03\\\\\n",
       "\tLag2 & 0.03 & -0.03 &  1.00 & -0.03 & -0.01 &  0.00 & -0.04 & -0.01\\\\\n",
       "\tLag3 & 0.03 & -0.01 & -0.03 &  1.00 & -0.02 & -0.02 & -0.04 &  0.00\\\\\n",
       "\tLag4 & 0.04 &  0.00 & -0.01 & -0.02 &  1.00 & -0.03 & -0.05 & -0.01\\\\\n",
       "\tLag5 & 0.03 & -0.01 &  0.00 & -0.02 & -0.03 &  1.00 & -0.02 & -0.03\\\\\n",
       "\tVolume & 0.54 &  0.04 & -0.04 & -0.04 & -0.05 & -0.02 &  1.00 &  0.01\\\\\n",
       "\tToday & 0.03 & -0.03 & -0.01 &  0.00 & -0.01 & -0.03 &  0.01 &  1.00\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 8 × 8 of type dbl\n",
       "\n",
       "| <!--/--> | Year | Lag1 | Lag2 | Lag3 | Lag4 | Lag5 | Volume | Today |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| Year | 1.00 |  0.03 |  0.03 |  0.03 |  0.04 |  0.03 |  0.54 |  0.03 |\n",
       "| Lag1 | 0.03 |  1.00 | -0.03 | -0.01 |  0.00 | -0.01 |  0.04 | -0.03 |\n",
       "| Lag2 | 0.03 | -0.03 |  1.00 | -0.03 | -0.01 |  0.00 | -0.04 | -0.01 |\n",
       "| Lag3 | 0.03 | -0.01 | -0.03 |  1.00 | -0.02 | -0.02 | -0.04 |  0.00 |\n",
       "| Lag4 | 0.04 |  0.00 | -0.01 | -0.02 |  1.00 | -0.03 | -0.05 | -0.01 |\n",
       "| Lag5 | 0.03 | -0.01 |  0.00 | -0.02 | -0.03 |  1.00 | -0.02 | -0.03 |\n",
       "| Volume | 0.54 |  0.04 | -0.04 | -0.04 | -0.05 | -0.02 |  1.00 |  0.01 |\n",
       "| Today | 0.03 | -0.03 | -0.01 |  0.00 | -0.01 | -0.03 |  0.01 |  1.00 |\n",
       "\n"
      ],
      "text/plain": [
       "       Year Lag1  Lag2  Lag3  Lag4  Lag5  Volume Today\n",
       "Year   1.00  0.03  0.03  0.03  0.04  0.03  0.54   0.03\n",
       "Lag1   0.03  1.00 -0.03 -0.01  0.00 -0.01  0.04  -0.03\n",
       "Lag2   0.03 -0.03  1.00 -0.03 -0.01  0.00 -0.04  -0.01\n",
       "Lag3   0.03 -0.01 -0.03  1.00 -0.02 -0.02 -0.04   0.00\n",
       "Lag4   0.04  0.00 -0.01 -0.02  1.00 -0.03 -0.05  -0.01\n",
       "Lag5   0.03 -0.01  0.00 -0.02 -0.03  1.00 -0.02  -0.03\n",
       "Volume 0.54  0.04 -0.04 -0.04 -0.05 -0.02  1.00   0.01\n",
       "Today  0.03 -0.03 -0.01  0.00 -0.01 -0.03  0.01   1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(cor(as.matrix(Smarket[,-9])),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `corrplot` package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful visualization of correlation matrices, especially with a large number of variables. \n",
    "\n",
    "See this [Vignette](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html) and examples in the package help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: corrplot\n",
      "corrplot 0.84 loaded\n"
     ]
    }
   ],
   "source": [
    "#install.packages(\"corrplot\",dependencies=TRUE,repos=\"https://cloud.r-project.org\")\n",
    "require(corrplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "R<-cor(Smarket[,-9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAFQCAMAAAClEhQnAAACYVBMVEUAAAAFMGEGMmQHNWgJ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\n2qp5AAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title \"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width=3.0, repr.plot.height=2.8)\n",
    "corrplot(R, method = \"ellipse\",type=\"upper\",tl.cex=0.6,cl.cex=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with `Smarket`, following Section 4.6 - Lab in the ISLR book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Code from the ISLR book](http://faculty.marshall.usc.edu/gareth-james/ISL/Chapter%204%20Lab.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Fisher's linear discriminant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E. $k$ Nearest Neighbours (k-NN) classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This _non-linear_ method clearly does not belong in a chapter on linear classification. Nevertheless it is easy both to describe and to implement, hence a useful reference for comparison to more sophisticated method.\n",
    "\n",
    "It requires a proximity or distance function in the predictor space, with which we evaluate the distances from a new case to be classified to each case in the learning dataset (whose class is already known). We select a positive integer $k$ (smaller than the number of cases in the learning dataset). Then the new observation is assigned to the  majority  class in the set of $k$ nearest cases in the learning dataset.\n",
    "\n",
    "In addition to being non-linear, $k-NN$ is the _most_ opposite method to those described above, in the sense of being _local,_ that is, the prediction function is constructed just within a neighbourhood of the new case, whereas in all previous methods the classification criterion is a partition of the predictor space by a _globally defined_ hyperplane. Different methods (least squares, logistic regression, Fisher discriminant) differ in the procedure used to derive this hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E1. With the `wine` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.url<-\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\n",
    "#wine<-read.csv(wine.url,header=FALSE)\n",
    "wine<-read.csv(\"wine.csv\",header=FALSE)\n",
    "colnames(wine)<-c(\"Type\",\"Alcohol\",\"Malic\",\"Ash\", \"Alcalinity\",\"Magnesium\",\"Phenols\",\"Flavonoids\",\n",
    "                  \"Nonflavonoids\",\"Proanthocyanins\",\"Color\",\"Hue\", \"Dilution\",\"Proline\")\n",
    "wine$Type <- as.factor(wine$Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Factor w/ 3 levels \"1\",\"2\",\"3\": 1 1 1 1 1 1 1 1 1 1 ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'1'</li>\n",
       "\t<li>'2'</li>\n",
       "\t<li>'3'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '1'\n",
       "\\item '2'\n",
       "\\item '3'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '1'\n",
       "2. '2'\n",
       "3. '3'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"1\" \"2\" \"3\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  2  3 \n",
       "59 71 48 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "str(wine$Type)\n",
    "levels(wine$Type)\n",
    "table(wine$Type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset in two subsets, for cross-validation, `train` with about $60\\%$ of data, and  `test` with the remaining $\\approx40\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "n<-nrow(wine)\n",
    "ntrain<-ceiling(0.6*n)\n",
    "ntest<-n-ntrain\n",
    "set.seed(24025)  # some arbitrary value, for the sake of reproducible results\n",
    "Itrain<-sample(1:n,ntrain,replace=FALSE)\n",
    "wine.train<-wine[Itrain,]\n",
    "wine.test<-wine[-Itrain,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain<-as.matrix(wine.train[,-1])\n",
    "ytrain<-wine.train[,1]\n",
    "Xtest<-as.matrix(wine.test[,-1])\n",
    "ytest<-wine.test[,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an implementation of k-NN classification in the `class` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: class\n"
     ]
    }
   ],
   "source": [
    "#install.packages(\"class\",dependencies=TRUE,repos=\"https://cloud.r-project.org\")\n",
    "require(class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Predicted\n",
       "True  1  2  3\n",
       "   1 19  1  1\n",
       "   2  4 18 10\n",
       "   3  2 11  5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k<-7\n",
    "y.hat<-knn(Xtrain,Xtest,ytrain,k )\n",
    "C<-table(\"True\"=ytest,\"Predicted\"=y.hat)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E2. With `SMarket`, following Section 4.6 - Lab in the ISLR book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E3. Caravan Insurance Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
